#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯è¯Šæ–­ç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•ä»åŸå§‹ç»„å­¦æ•°æ®åˆ°æœ€ç»ˆè¯Šæ–­æŠ¥å‘Šçš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®é¢„å¤„ç†
- ä¸“å®¶é¢„æµ‹
- å†²çªæ£€æµ‹
- è¾©è®ºç³»ç»Ÿï¼ˆLangGraphï¼‰
- CMOå†³ç­–
- æŠ¥å‘Šç”Ÿæˆ

ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹å’Œç”Ÿæˆçš„è®­ç»ƒæ•°æ®ã€‚
"""

import sys
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
import asyncio

from clinical.preprocessing.microbiome_preprocessor import MicrobiomePreprocessor
from clinical.preprocessing.metabolome_preprocessor import MetabolomePreprocessor
from clinical.preprocessing.proteome_preprocessor import ProteomePreprocessor
from clinical.experts.model_manager import ModelManager
from clinical.decision.conflict_resolver import ConflictResolver
from clinical.decision.cmo_coordinator import CMOCoordinator
from clinical.decision.report_generator import ReportGenerator
from clinical.models.expert_opinion import ExpertOpinion, FeatureImportance


# =============================================================================
# Mockæ•°æ®ç”Ÿæˆå‡½æ•°
# =============================================================================

def create_mock_rag_context(query: str) -> Dict[str, Any]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„RAGæŸ¥è¯¢ç»“æœ"""
    return {
        "query": query,
        "documents": [
            {
                "source": "PubMed:12345678",
                "title": "Periodontal Disease and Oral Microbiome",
                "content": "P. gingivalis is a key pathogen in periodontitis. Elevated levels of this bacteria correlate with disease severity and tissue destruction.",
                "score": 0.92,
                "url": "https://pubmed.ncbi.nlm.nih.gov/12345678"
            },
            {
                "source": "Clinical Guidelines 2023",
                "title": "Diagnosis and Treatment of Periodontitis",
                "content": "Clinical diagnosis requires elevated MMP-9 and IL-6 inflammatory markers, combined with microbiome analysis showing pathogenic bacteria.",
                "score": 0.87,
                "url": ""
            },
            {
                "source": "J Clin Microbiol 2024",
                "title": "Butyrate Production and Periodontal Health",
                "content": "Butyrate produced by anaerobic bacteria is a key metabolite in periodontitis pathogenesis.",
                "score": 0.83,
                "url": ""
            }
        ]
    }


def create_mock_cag_context(diagnosis: str) -> Dict[str, Any]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„CAGæŸ¥è¯¢ç»“æœ"""
    return {
        "query_features": {"P_gingivalis": 0.22, "Butyrate": 0.18, "MMP9": 0.25},
        "similar_cases": [
            {
                "case_id": "CASE_2023_001",
                "diagnosis": diagnosis,
                "similarity": 0.89,
                "outcome": "Successful treatment with scaling and root planing",
                "key_features": {
                    "P_gingivalis": 0.22,
                    "Butyrate": 0.18,
                    "MMP9": 0.25
                }
            },
            {
                "case_id": "CASE_2023_045",
                "diagnosis": diagnosis,
                "similarity": 0.85,
                "outcome": "Required advanced periodontal therapy",
                "key_features": {
                    "P_gingivalis": 0.20,
                    "Butyrate": 0.16,
                    "MMP9": 0.23
                }
            }
        ]
    }


# =============================================================================
# æµ‹è¯•åœºæ™¯ç±»
# =============================================================================

class TestScenario:
    """æµ‹è¯•åœºæ™¯åŸºç±»"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.start_time = None
        self.end_time = None
        self.results = {}

    def start(self):
        """å¼€å§‹æµ‹è¯•"""
        print("\n" + "=" * 70)
        print(f"åœºæ™¯: {self.name}")
        print("=" * 70)
        print(f"æè¿°: {self.description}")
        print("-" * 70)
        self.start_time = time.time()

    def end(self, success: bool = True):
        """ç»“æŸæµ‹è¯•"""
        self.end_time = time.time()
        duration = self.end_time - self.start_time
        status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
        print("-" * 70)
        print(f"{status} (æ‰§è¡Œæ—¶é—´: {duration:.2f}s)")
        print("=" * 70)
        return success

    def checkpoint(self, name: str, success: bool = True, details: str = ""):
        """æµ‹è¯•æ£€æŸ¥ç‚¹"""
        symbol = "âœ“" if success else "âœ—"
        print(f"{symbol} {name}", end="")
        if details:
            print(f": {details}")
        else:
            print()
        self.results[name] = {"success": success, "details": details}


# =============================================================================
# åœºæ™¯1: æ— å†²çªå¿«é€Ÿå†³ç­–
# =============================================================================

class NoConflictScenario(TestScenario):
    """åœºæ™¯1: æ‰€æœ‰ä¸“å®¶ä¸€è‡´è¯Šæ–­Periodontitis"""

    def __init__(self):
        super().__init__(
            name="åœºæ™¯1: æ— å†²çªå¿«é€Ÿå†³ç­–",
            description="æ‰€æœ‰3ä¸ªä¸“å®¶ä¸€è‡´è¯Šæ–­ä¸ºPeriodontitisï¼Œæµ‹è¯•å¿«é€Ÿå†³ç­–è·¯å¾„"
        )

    async def run(self, model_manager: ModelManager) -> bool:
        """è¿è¡Œæµ‹è¯•åœºæ™¯"""
        self.start()

        try:
            # åŠ è½½æ•°æ®
            microbiome_data = pd.read_csv("data/training/microbiome_raw.csv", index_col=0)
            metabolome_data = pd.read_csv("data/training/metabolome_raw.csv", index_col=0)
            proteome_data = pd.read_csv("data/training/proteome_raw.csv", index_col=0)
            labels = pd.read_csv("data/training/labels.csv", index_col=0)
            with open("data/training/splits.json", "r") as f:
                splits = json.load(f)

            # é€‰æ‹©æµ‹è¯•é›†ä¸­çš„Periodontitisæ ·æœ¬
            test_ids = splits['test']
            periodontitis_ids = [
                idx for idx in test_ids
                if idx.startswith("Periodontitis_") and labels.loc[idx, "diagnosis"] == "Periodontitis"
            ]

            if not periodontitis_ids:
                self.checkpoint("æ•°æ®åŠ è½½", False, "æ²¡æœ‰æ‰¾åˆ°Periodontitisæµ‹è¯•æ ·æœ¬")
                return self.end(False)

            # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            sample_id = periodontitis_ids[0]
            micro_sample = microbiome_data.loc[[sample_id]]
            metab_sample = metabolome_data.loc[[sample_id]]
            prot_sample = proteome_data.loc[[sample_id]]

            self.checkpoint("æ•°æ®åŠ è½½", True, f"æ ·æœ¬ID: {sample_id}")

            # é¢„å¤„ç†
            micro_preprocessor = MicrobiomePreprocessor()
            metab_preprocessor = MetabolomePreprocessor()
            prot_preprocessor = ProteomePreprocessor()

            micro_processed = micro_preprocessor.fit_transform(micro_sample).data
            metab_processed = metab_preprocessor.fit_transform(metab_sample).data
            prot_processed = prot_preprocessor.fit_transform(prot_sample).data

            self.checkpoint("æ•°æ®é¢„å¤„ç†", True, f"å½¢çŠ¶: {micro_processed.shape}, {metab_processed.shape}, {prot_processed.shape}")

            # åŠ è½½ä¸“å®¶æ¨¡å‹å¹¶é¢„æµ‹
            experts = model_manager.load_all_experts()

            micro_opinion = experts['microbiome_expert'].predict(micro_processed)[0]
            metab_opinion = experts['metabolome_expert'].predict(metab_processed)[0]
            prot_opinion = experts['proteome_expert'].predict(prot_processed)[0]

            opinions = [micro_opinion, metab_opinion, prot_opinion]

            self.checkpoint("ä¸“å®¶é¢„æµ‹", True)
            print(f"  - Microbiome: {micro_opinion.diagnosis} (prob={micro_opinion.probability:.2f}, conf={micro_opinion.confidence:.2f})")
            print(f"  - Metabolome: {metab_opinion.diagnosis} (prob={metab_opinion.probability:.2f}, conf={metab_opinion.confidence:.2f})")
            print(f"  - Proteome: {prot_opinion.diagnosis} (prob={prot_opinion.probability:.2f}, conf={prot_opinion.confidence:.2f})")

            # å†²çªæ£€æµ‹
            resolver = ConflictResolver()
            conflict_analysis = resolver.detect_conflict(opinions)

            has_conflict = conflict_analysis.has_conflict
            self.checkpoint("å†²çªæ£€æµ‹", not has_conflict, f"å†²çª: {has_conflict}")

            # CMOå†³ç­–
            cmo = CMOCoordinator()
            if has_conflict:
                print("  è­¦å‘Š: æ£€æµ‹åˆ°å†²çªï¼ˆé¢„æœŸæ— å†²çªï¼‰")
                # å³ä½¿æœ‰å†²çªä¹Ÿç»§ç»­æµ‹è¯•
                diagnosis_result = await cmo.make_conflict_resolution(
                    expert_opinions=opinions,
                    conflict_analysis=conflict_analysis,
                    patient_metadata={"patient_id": sample_id},
                    rag_context=create_mock_rag_context("Periodontitis diagnosis"),
                    cag_context=create_mock_cag_context("Periodontitis")
                )
            else:
                diagnosis_result = await cmo.make_quick_decision(
                    expert_opinions=opinions,
                    conflict_analysis=conflict_analysis
                )
                diagnosis_result.patient_id = sample_id

            self.checkpoint("CMOå†³ç­–", True, f"{diagnosis_result.diagnosis} (ç½®ä¿¡åº¦: {diagnosis_result.confidence:.2f})")

            # æŠ¥å‘Šç”Ÿæˆ
            report_gen = ReportGenerator()
            report = report_gen.generate_report(diagnosis_result)

            self.checkpoint("æŠ¥å‘Šç”Ÿæˆ", len(report) > 100, f"é•¿åº¦: {len(report)} å­—ç¬¦")

            # ä¿å­˜æŠ¥å‘Š
            report_path = Path("data/test") / "scenario1_report.md"
            report_path.parent.mkdir(parents=True, exist_ok=True)
            report_gen.save_report(report, str(report_path))

            self.checkpoint("æŠ¥å‘Šä¿å­˜", report_path.exists(), f"è·¯å¾„: {report_path}")

            return self.end(True)

        except Exception as e:
            print(f"\nâœ— é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self.end(False)


# =============================================================================
# åœºæ™¯2: è¾¹ç•Œå†²çªï¼ˆé€šè¿‡é˜ˆå€¼è°ƒæ•´è§£å†³ï¼‰
# =============================================================================

class BorderlineConflictScenario(TestScenario):
    """åœºæ™¯2: 2ä¸ªä¸“å®¶ä¸€è‡´ï¼Œ1ä¸ªè¾¹ç•Œå€¼"""

    def __init__(self):
        super().__init__(
            name="åœºæ™¯2: è¾¹ç•Œå†²çª",
            description="2ä¸ªä¸“å®¶è¯Šæ–­Periodontitisï¼Œ1ä¸ªä¸“å®¶è¾¹ç•Œå€¼ï¼Œæµ‹è¯•é˜ˆå€¼è°ƒæ•´"
        )

    async def run(self, model_manager: ModelManager) -> bool:
        """è¿è¡Œæµ‹è¯•åœºæ™¯"""
        self.start()

        try:
            # ä¸ºäº†åˆ›å»ºè¾¹ç•Œæƒ…å†µï¼Œæˆ‘ä»¬ä½¿ç”¨Mockä¸“å®¶æ„è§
            # å®é™…åœºæ™¯ä¸­å¯ä»¥é€šè¿‡æ··åˆæ•°æ®æˆ–è°ƒæ•´é˜ˆå€¼å®ç°

            opinions = [
                ExpertOpinion(
                    expert_name="microbiome_expert",
                    omics_type="microbiome",
                    diagnosis="Periodontitis",
                    probability=0.88,
                    confidence=0.92,
                    biological_explanation="HIGH levels of P.gingivalis (22x) and T.denticola (20x) detected",
                    top_features=[
                        FeatureImportance("Porphyromonas_gingivalis", 0.40, "up", "Major periodontal pathogen"),
                        FeatureImportance("Treponema_denticola", 0.32, "up", "Periodontal spirochete"),
                        FeatureImportance("Prevotella_intermedia", 0.15, "up", "Opportunistic pathogen")
                    ],
                    evidence_chain=["Strong pathogenic signal", "Consistent with periodontal disease"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5}
                ),
                ExpertOpinion(
                    expert_name="metabolome_expert",
                    omics_type="metabolome",
                    diagnosis="Periodontitis",
                    probability=0.86,
                    confidence=0.90,
                    biological_explanation="HIGH butyrate (28x) and propionate (25x) levels",
                    top_features=[
                        FeatureImportance("Butyrate", 0.38, "up", "Inflammatory metabolite"),
                        FeatureImportance("Propionate", 0.35, "up", "Bacterial fermentation product"),
                        FeatureImportance("Acetate", 0.12, "up", "Short-chain fatty acid")
                    ],
                    evidence_chain=["Elevated inflammatory metabolites", "Supports periodontal diagnosis"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5}
                ),
                ExpertOpinion(
                    expert_name="proteome_expert",
                    omics_type="proteome",
                    diagnosis="Healthy",
                    probability=0.55,  # è¾¹ç•Œå€¼
                    confidence=0.60,
                    biological_explanation="IgA levels slightly elevated but MMP9 also present (mixed signals)",
                    top_features=[
                        FeatureImportance("IgA", 0.30, "up", "Protective antibody"),
                        FeatureImportance("MMP9", 0.28, "up", "Matrix metalloproteinase"),
                        FeatureImportance("IL6", 0.25, "up", "Inflammatory cytokine")
                    ],
                    evidence_chain=["Mixed signals detected", "Borderline classification"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5, "borderline": True}
                )
            ]

            self.checkpoint("åˆ›å»ºMockä¸“å®¶æ„è§", True, "3ä¸ªä¸“å®¶")

            for i, op in enumerate(opinions, 1):
                print(f"  {i}. {op.expert_name}: {op.diagnosis} (prob={op.probability:.2f}, conf={op.confidence:.2f})")

            # å†²çªæ£€æµ‹
            resolver = ConflictResolver()
            conflict_analysis = resolver.detect_conflict(opinions)

            has_conflict = conflict_analysis.has_conflict
            self.checkpoint("å†²çªæ£€æµ‹", has_conflict, f"å†²çªç±»å‹: {[ct.value for ct in conflict_analysis.conflict_types]}")

            # CMOå†³ç­–ï¼ˆæœ‰å†²çªï¼‰
            cmo = CMOCoordinator()
            diagnosis_result = await cmo.make_conflict_resolution(
                expert_opinions=opinions,
                conflict_analysis=conflict_analysis,
                patient_metadata={"patient_id": "BORDERLINE_TEST_001"},
                rag_context=create_mock_rag_context("Periodontitis vs Healthy differential"),
                cag_context=create_mock_cag_context("Periodontitis")
            )
            diagnosis_result.patient_id = "BORDERLINE_TEST_001"

            self.checkpoint("CMOå†²çªè§£å†³", True, f"{diagnosis_result.diagnosis} (ç½®ä¿¡åº¦: {diagnosis_result.confidence:.2f})")

            # æŠ¥å‘Šç”Ÿæˆ
            report_gen = ReportGenerator()
            report = report_gen.generate_report(diagnosis_result)

            self.checkpoint("æŠ¥å‘Šç”Ÿæˆ", len(report) > 100)

            # ä¿å­˜æŠ¥å‘Š
            report_path = Path("data/test") / "scenario2_report.md"
            report_gen.save_report(report, str(report_path))

            self.checkpoint("æŠ¥å‘Šä¿å­˜", report_path.exists())

            return self.end(True)

        except Exception as e:
            print(f"\nâœ— é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self.end(False)


# =============================================================================
# åœºæ™¯3: å¼ºå†²çªï¼ˆéœ€è¦RAG/CAGï¼‰
# =============================================================================

class StrongConflictScenario(TestScenario):
    """åœºæ™¯3: ä¸‰ä¸ªä¸“å®¶å®Œå…¨ä¸ä¸€è‡´"""

    def __init__(self):
        super().__init__(
            name="åœºæ™¯3: å¼ºå†²çªéœ€è¦RAG/CAG",
            description="3ä¸ªä¸“å®¶å®Œå…¨ä¸ä¸€è‡´ï¼Œæµ‹è¯•è¾©è®ºç³»ç»Ÿå’ŒRAG/CAGè§¦å‘"
        )

    async def run(self, model_manager: ModelManager) -> bool:
        """è¿è¡Œæµ‹è¯•åœºæ™¯"""
        self.start()

        try:
            # åˆ›å»ºå¼ºå†²çªçš„Mockä¸“å®¶æ„è§
            opinions = [
                ExpertOpinion(
                    expert_name="microbiome_expert",
                    omics_type="microbiome",
                    diagnosis="Periodontitis",
                    probability=0.85,
                    confidence=0.90,
                    biological_explanation="HIGH levels of P.gingivalis (20x) and T.denticola (18x) detected",
                    top_features=[
                        FeatureImportance("Porphyromonas_gingivalis", 0.35, "up", "Pathogenic bacteria"),
                        FeatureImportance("Treponema_denticola", 0.28, "up", "Periodontal pathogen"),
                        FeatureImportance("Fusobacterium_nucleatum", 0.15, "up", "Inflammatory bacteria")
                    ],
                    evidence_chain=["High pathogenic bacteria detected", "Consistent with periodontal disease"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5}
                ),
                ExpertOpinion(
                    expert_name="metabolome_expert",
                    omics_type="metabolome",
                    diagnosis="Diabetes",
                    probability=0.82,
                    confidence=0.88,
                    biological_explanation="HIGH glucose (25x) and lactate (22x) levels",
                    top_features=[
                        FeatureImportance("Glucose", 0.40, "up", "Elevated blood sugar"),
                        FeatureImportance("Lactate", 0.32, "up", "Metabolic dysfunction"),
                        FeatureImportance("Pyruvate", 0.12, "up", "Energy metabolism issue")
                    ],
                    evidence_chain=["Elevated glucose detected", "Metabolic profile suggests diabetes"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5}
                ),
                ExpertOpinion(
                    expert_name="proteome_expert",
                    omics_type="proteome",
                    diagnosis="Healthy",
                    probability=0.78,
                    confidence=0.85,
                    biological_explanation="HIGH protective IgA (22x) and Lactoferrin (20x)",
                    top_features=[
                        FeatureImportance("IgA", 0.38, "up", "Protective antibody"),
                        FeatureImportance("Lactoferrin", 0.30, "up", "Antimicrobial protein"),
                        FeatureImportance("Lysozyme", 0.15, "up", "Enzyme protection")
                    ],
                    evidence_chain=["High protective proteins detected", "Immune system functioning well"],
                    model_metadata={"version": "v1.0.0", "threshold": 0.5}
                )
            ]

            self.checkpoint("åˆ›å»ºå¼ºå†²çªMockæ„è§", True, "3ä¸ªä¸“å®¶å®Œå…¨ä¸ä¸€è‡´")

            for i, op in enumerate(opinions, 1):
                print(f"  {i}. {op.expert_name}: {op.diagnosis} (prob={op.probability:.2f}, conf={op.confidence:.2f})")

            # å†²çªæ£€æµ‹
            resolver = ConflictResolver()
            conflict_analysis = resolver.detect_conflict(opinions)

            self.checkpoint("å†²çªæ£€æµ‹", conflict_analysis.has_conflict,
                          f"å†²çªç±»å‹: {[ct.value for ct in conflict_analysis.conflict_types]}")
            print(f"  éœ€è¦è¾©è®º: {conflict_analysis.requires_debate}")
            print(f"  éœ€è¦RAG: {conflict_analysis.requires_rag}")
            print(f"  éœ€è¦CAG: {conflict_analysis.requires_cag}")

            # CMOå†³ç­–ï¼ˆå¼ºå†²çªï¼‰
            cmo = CMOCoordinator()
            diagnosis_result = await cmo.make_conflict_resolution(
                expert_opinions=opinions,
                conflict_analysis=conflict_analysis,
                patient_metadata={"patient_id": "CONFLICT_TEST_001"},
                rag_context=create_mock_rag_context("Periodontitis vs Diabetes vs Healthy differential"),
                cag_context=create_mock_cag_context("Periodontitis"),  # CMOä¼šä¼˜å…ˆé€‰æ‹©
                debate_history=[]  # æ¨¡æ‹Ÿè¾©è®ºå†å²ï¼ˆå®é™…ç”±DebateSystemç”Ÿæˆï¼‰
            )
            diagnosis_result.patient_id = "CONFLICT_TEST_001"

            self.checkpoint("CMOå†²çªè§£å†³", True,
                          f"{diagnosis_result.diagnosis} (ç½®ä¿¡åº¦: {diagnosis_result.confidence:.2f})")

            # æ£€æŸ¥å†²çªè§£å†³è®°å½•
            if diagnosis_result.conflict_resolution:
                cr = diagnosis_result.conflict_resolution
                print(f"  è§£å†³æ–¹æ³•: {cr.resolution_method}")
                print(f"  RAGè¯æ®æ•°: {len(cr.rag_evidence)}")
                print(f"  CAGæ¡ˆä¾‹æ•°: {len(cr.cag_cases)}")
                self.checkpoint("å†²çªè§£å†³è®°å½•", True, f"ä½¿ç”¨{cr.resolution_method}")

            # æŠ¥å‘Šç”Ÿæˆ
            report_gen = ReportGenerator()
            report = report_gen.generate_report(diagnosis_result)

            self.checkpoint("æŠ¥å‘Šç”Ÿæˆ", len(report) > 100)

            # ä¿å­˜æŠ¥å‘Š
            report_path = Path("data/test") / "scenario3_report.md"
            report_gen.save_report(report, str(report_path))

            self.checkpoint("æŠ¥å‘Šä¿å­˜", report_path.exists())

            return self.end(True)

        except Exception as e:
            print(f"\nâœ— é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self.end(False)


# =============================================================================
# ä¸»æµ‹è¯•è¿è¡Œå™¨
# =============================================================================

async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯"""
    print("\n" + "#" * 70)
    print("# ç«¯åˆ°ç«¯è¯Šæ–­ç³»ç»Ÿæµ‹è¯•")
    print("#" * 70)
    print("\næµ‹è¯•ç›®æ ‡:")
    print("  1. éªŒè¯å®Œæ•´è¯Šæ–­æµç¨‹ï¼ˆæ•°æ®â†’é¢„å¤„ç†â†’ä¸“å®¶â†’å†²çªæ£€æµ‹â†’CMOâ†’æŠ¥å‘Šï¼‰")
    print("  2. æµ‹è¯•3ç§åœºæ™¯ï¼ˆæ— å†²çªã€è¾¹ç•Œå†²çªã€å¼ºå†²çªï¼‰")
    print("  3. éªŒè¯RAG/CAGè§¦å‘æœºåˆ¶")
    print("  4. éªŒè¯CMOå†³ç­–é€»è¾‘\n")

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("=" * 70)
    print("åˆå§‹åŒ–ç³»ç»Ÿ")
    print("=" * 70)

    try:
        model_manager = ModelManager(models_dir="data/models")
        print("âœ“ ModelManageråˆå§‹åŒ–æˆåŠŸ")

        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        model_files = list(Path("data/models").glob("*_expert_*.pkl"))
        print(f"âœ“ æ‰¾åˆ°{len(model_files)}ä¸ªæ¨¡å‹æ–‡ä»¶")

        if len(model_files) < 3:
            print("\nâœ— é”™è¯¯: ç¼ºå°‘è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
            print("  è¯·å…ˆè¿è¡Œ: python scripts/train_with_generated_data.py")
            return

    except Exception as e:
        print(f"\nâœ— åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # è¿è¡Œæµ‹è¯•åœºæ™¯
    scenarios = [
        NoConflictScenario(),
        BorderlineConflictScenario(),
        StrongConflictScenario()
    ]

    results = []
    total_start = time.time()

    for scenario in scenarios:
        success = await scenario.run(model_manager)
        results.append({
            "name": scenario.name,
            "success": success,
            "duration": scenario.end_time - scenario.start_time if scenario.end_time else 0
        })

    total_duration = time.time() - total_start

    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)

    passed = sum(1 for r in results if r["success"])
    total = len(results)

    for r in results:
        status = "âœ“ é€šè¿‡" if r["success"] else "âœ— å¤±è´¥"
        print(f"{status}: {r['name']} ({r['duration']:.2f}s)")

    print(f"\næ€»è®¡: {passed}/{total} åœºæ™¯é€šè¿‡")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_duration:.2f}s")

    if passed == total:
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¯Šæ–­ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        print("=" * 70)
        print("\nç”Ÿæˆçš„æŠ¥å‘Š:")
        for i in range(1, 4):
            report_path = Path(f"data/test/scenario{i}_report.md")
            if report_path.exists():
                print(f"  - {report_path}")
    else:
        print("\n" + "=" * 70)
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("=" * 70)


if __name__ == "__main__":
    asyncio.run(main())
